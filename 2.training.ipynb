{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldPqdeg5JQ0c"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34130,
     "status": "ok",
     "timestamp": 1635876494508,
     "user": {
      "displayName": "Kenan KOCADURDU",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11623489172164073063"
     },
     "user_tz": -180
    },
    "id": "pTpC6MYHx-Qv",
    "outputId": "20f4c0cb-de69-40e7-b412-799959e5354b"
   },
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.vision.all import *\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtdsBjZaJbeg",
    "tags": []
   },
   "source": [
    "## PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17186,
     "status": "ok",
     "timestamp": 1635876512386,
     "user": {
      "displayName": "Kenan KOCADURDU",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11623489172164073063"
     },
     "user_tz": -180
    },
    "id": "fN03CjAEyPIC",
    "outputId": "7a53161d-e6ac-43a8-9246-b89e0e68d972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "TRAIN\n",
      "--------------------------------------------------\n",
      "Number of Background \t\t: 10\n",
      "Number of Maya \t\t\t: 10\n",
      "Number of Negative Basil\t: 10\n",
      "Number of Negative Coco\t\t: 11\n",
      "Number of Positive Chain\t: 10\n",
      "Number of Positive Cluster\t: 10\n",
      "--------------------------------------------------\n",
      "\t\t\tTOTAL \t: 61\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "path_train = Path('gram_stain/')\n",
    "train_fnames = get_image_files(path_train)\n",
    "\n",
    "background_fnames_train = get_image_files(path_train/'background')\n",
    "maya_fnames_train = get_image_files(path_train/'maya')\n",
    "neg_basil_fnames_train = get_image_files(path_train/'neg_basil')\n",
    "neg_coco_fnames_train = get_image_files(path_train/'neg_coco')\n",
    "pos_chain_fnames_train = get_image_files(path_train/'pos_chain')\n",
    "pos_cluster_fnames_train = get_image_files(path_train/'pos_cluster')\n",
    "\n",
    "print('-'*50)\n",
    "print('TRAIN')\n",
    "print('-'*50)\n",
    "print('Number of Background \\t\\t: '+ str(len(background_fnames_train)))\n",
    "print('Number of Maya \\t\\t\\t: '+ str(len(maya_fnames_train)))\n",
    "print('Number of Negative Basil\\t: '+ str(len(neg_basil_fnames_train)))\n",
    "print('Number of Negative Coco\\t\\t: '+ str(len(neg_coco_fnames_train)))\n",
    "print('Number of Positive Chain\\t: '+ str(len(pos_chain_fnames_train)))\n",
    "print('Number of Positive Cluster\\t: '+ str(len(pos_cluster_fnames_train)))\n",
    "print('-'*50)\n",
    "print('\\t\\t\\tTOTAL \\t: '+ str(len(train_fnames)))\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_COLS = ['background', 'maya', 'neg_basil', 'neg_coco', 'pos_chain', 'pos_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maya</td>\n",
       "      <td>gram_stain/maya/e83b3a4c-3472-11ee-8605-48b02dd3da7b.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_cluster</td>\n",
       "      <td>gram_stain/pos_cluster/f546b126-3472-11ee-8605-48b02dd3da7b.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg_basil</td>\n",
       "      <td>gram_stain/neg_basil/ea986832-3472-11ee-8605-48b02dd3da7b.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maya</td>\n",
       "      <td>gram_stain/maya/e8cbf87a-3472-11ee-8605-48b02dd3da7b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>background</td>\n",
       "      <td>gram_stain/background/e50585da-3472-11ee-8605-48b02dd3da7b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  \\\n",
       "0         maya   \n",
       "1  pos_cluster   \n",
       "2    neg_basil   \n",
       "3         maya   \n",
       "4   background   \n",
       "\n",
       "                                                          filepath  fold  \n",
       "0         gram_stain/maya/e83b3a4c-3472-11ee-8605-48b02dd3da7b.jpg     2  \n",
       "1  gram_stain/pos_cluster/f546b126-3472-11ee-8605-48b02dd3da7b.jpg     2  \n",
       "2    gram_stain/neg_basil/ea986832-3472-11ee-8605-48b02dd3da7b.jpg     2  \n",
       "3         gram_stain/maya/e8cbf87a-3472-11ee-8605-48b02dd3da7b.jpg     1  \n",
       "4   gram_stain/background/e50585da-3472-11ee-8605-48b02dd3da7b.jpg     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_list = glob.glob('gram_stain/*/*.jpg')\n",
    "labels = [str(filepath_list[i]).split(\"/\")[-2] for i in range(len(filepath_list))]\n",
    "\n",
    "filepath = pd.Series(filepath_list, name='filepath').astype(str)\n",
    "label = pd.Series(labels, name='label')\n",
    "\n",
    "train_df = pd.concat([label, filepath], axis=1)\n",
    "train_df = train_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "N_FOLDS = 5\n",
    "train_df['fold'] = -1\n",
    "strat_kfold = MultilabelStratifiedKFold(n_splits=N_FOLDS, random_state=43, shuffle=True)\n",
    "for i, (_, test_index) in enumerate(strat_kfold.split(train_df.filepath.values, train_df.iloc[:,1:].values)):\n",
    "    train_df.iloc[test_index, -1] = i\n",
    "train_df['fold'] = train_df['fold'].astype('int')\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv7lE1LXJfmp"
   },
   "source": [
    "## AUGS AND DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs_train = []\n",
    "\n",
    "def get_data(fold):\n",
    "    train_df_fold = ((train_df.loc[train_df.fold==fold]).reset_index(drop=True)).index\n",
    "    dblock = DataBlock(blocks=(ImageBlock(cls=PILImage), CategoryBlock(vocab=LABEL_COLS)),\n",
    "                       splitter=IndexSplitter(train_df_fold),\n",
    "                       get_x=ColReader('filepath'),\n",
    "                       get_y=ColReader('label'),\n",
    "                       item_tfms=Resize(300, method=\"squish\"),\n",
    "                       batch_tfms=augs_train,\n",
    "                       )\n",
    "    dls = dblock.dataloaders(train_df, bs=2)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn_rate = 1e-04\n",
    "reduce_patience= 3\n",
    "stop_patience = 5\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.122701</td>\n",
       "      <td>5.117309</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>01:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.156076</td>\n",
       "      <td>9.934793</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.255619</td>\n",
       "      <td>8.288945</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.018598</td>\n",
       "      <td>3.020062</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.175947</td>\n",
       "      <td>2.633605</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.922782</td>\n",
       "      <td>2.763947</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.882091</td>\n",
       "      <td>2.839972</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.981508</td>\n",
       "      <td>2.801339</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.004668</td>\n",
       "      <td>2.386480</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.890116</td>\n",
       "      <td>2.410639</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 5.117309093475342.\n",
      "Better model found at epoch 3 with valid_loss value: 3.020061731338501.\n",
      "Better model found at epoch 4 with valid_loss value: 2.633605480194092.\n",
      "Epoch 7: reducing lr to 1.7197876422966228e-06\n",
      "Better model found at epoch 8 with valid_loss value: 2.386479616165161.\n"
     ]
    }
   ],
   "source": [
    "for f_i in np.arange(0, 1, 1):\n",
    "    dls = get_data(f_i)\n",
    "    learner_cnn = cnn_learner(dls, models.mobilenet_v2, cut=-1, pretrained=False, normalize=True, loss_func=CrossEntropyLossFlat(), opt_func=Adam, metrics=[accuracy] )\n",
    "    #learner_cnn = cnn_learner(dls, xresnet50, normalize=True, n_out=len(dls.vocab), loss_func=CrossEntropyLossFlat(), opt_func=Adam, metrics=[accuracy])\n",
    "    \n",
    "    learner_cnn.fit_one_cycle(epoch, lr_max=learn_rate,\n",
    "                                cbs=[\n",
    "                                    SaveModelCallback(monitor='valid_loss', min_delta=0.0001, fname=\"mobilenet_fold_\" +str(f_i)),\n",
    "                                    ReduceLROnPlateau(monitor='valid_loss', min_delta=0.01, patience=reduce_patience),\n",
    "                                    EarlyStoppingCallback(monitor='valid_loss', min_delta=0.0001, patience=stop_patience)\n",
    "                                    ]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## camera"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "camera = CSICamera(width=300, height=300, capture_device=0)\n",
    "camera.running = True\n",
    "print(\"camera created\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## camera_widget"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "camera.unobserve_all()\n",
    "camera_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "camera_view_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget])\n",
    "])\n",
    "print(\"camera_view_widget created\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dls = get_data(0)\n",
    "learner_cnn = cnn_learner(dls, models.mobilenet_v2, cut=-1, normalize=True, loss_func=CrossEntropyLossFlat(), opt_func=Adam, metrics=[accuracy] ).load('xresnet18_fold_0')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    image = camera.value\n",
    "    image_, = first(dls.test_dl([image]))\n",
    "    image_ = TensorImage(dls.train.decode((image_,))[0][0])\n",
    "    tani_, tani_id, prob_list_ = learner_cnn.predict(image_)\n",
    "    print(tani_)\n",
    "    print(prob_list_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## live_execution_widget"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import threading\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "prediction_widget = ipywidgets.Text(description='prediction')\n",
    "\n",
    "def live(state_widget, datal, model, camera, prediction_widget):\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.value\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_, = first(datal.test_dl([image]))\n",
    "            image_ = TensorImage(datal.train.decode((image_,))[0][0])\n",
    "            tani_, tani_id, prob_list_ = model.predict(image_)\n",
    "            prediction_widget.value = tani_\n",
    "            \n",
    "def start_live(change):\n",
    "    dls = get_data(0)\n",
    "    learner_cnn = cnn_learner(dls, models.mobilenet_v2, cut=-1, normalize=True, loss_func=CrossEntropyLossFlat(), opt_func=Adam, metrics=[accuracy] ).load('xresnet18_fold_0')\n",
    "    #learner_cnn = cnn_learner(dls, xresnet50, normalize=True, loss_func=CrossEntropyLossFlat(), opt_func=Adam, metrics=[accuracy] ).load('xresnet50')\n",
    "    \n",
    "    \n",
    "    if change['new'] == 'live':\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, dls, learner_cnn, camera, prediction_widget))\n",
    "        execute_thread.start()\n",
    "\n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "print(\"live_execution_widget created\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_view_widget, live_execution_widget]), \n",
    "])\n",
    "\n",
    "display(all_widget)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import IPython\n",
    "if type(camera) is CSICamera:\n",
    "    print(\"Ignore 'Exception in thread' tracebacks\\n\")\n",
    "    camera.cap.release()\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "0_Chest_XRay_xresnet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
